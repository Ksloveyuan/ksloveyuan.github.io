[{"content":" 自律给我自由。\n ","href":"/","title":"Home"},{"content":"","href":"/posts/","title":"Posts"},{"content":"我是\n 一名会点前端的后端程序员，偏偏对区块链最感兴趣。\n 相信\n 自律给我自由。\n ","href":"/authors/me/","title":"About Me"},{"content":"","href":"/categories/","title":"Categories"},{"content":"","href":"/tags/https/","title":"Https"},{"content":"","href":"/tags/nginx/","title":"Nginx"},{"content":"","href":"/tags/","title":"Tags"},{"content":" 前言 话说，刚刚过去的周六下午（ 我们是调休，可不是996哦 ），测试同学突然大叫，\n 网站、小程序，怎么所有的功能都不work了!\n 当时，那可是真的慌呀 \u0026gt;_\u0026lt;!!\n还好强大的chrome第一时间提示，网站的SSL证书过期了。赶紧第一时间联系CTO，给证书绪个费。然后运维同学依次给服务器、CDN服务更新了证书，看到网站和小程序又可以访问了，大家都松了一口气，吐槽了一番，就开心过周末去了。\n哪知道，周一刚回来，就听到运营的同学说有的客户反应一些爬虫和客户端服务程序都不工作了。\n排查 几位后端的同学赶紧查了一通日志，发现很多后台的长驻服务，以及客户端的程序都是在调用登录接口的时候失败。\n奇怪的是同样的https接口，浏览器中的前端程序调用就没问题，后端同学用postman调用就是失败的。根据postman的提示，把ssl关了一切就又好了。\n一时间，大家都有些懵，虽说直觉告诉我一定和证书过期有关系，但是该更新的地方都更新了，问题会出在哪了？是不是有地方忘记更新了？\n整个上午，百度、bing、google，搜索了大量nginx+https的文章，却大同小异。\n话说该配置的都配置了，会不会是证书有问题呢？这个想法一闪而过的瞬间，下意识的 ll ，让我注意到了新的证书和备份的旧证书文件大小差了5kb。3kb VS 8kb，这个差距可不能忽略！\n赶紧找运维同学重新下载了证书文件。\n++咦？惊喜的发现第二个文件和第三个文件加起了不正好是8kb吗，这应该不是巧合。++\n心想死马当活马医吧，把两文件一合并，扔到了服务上。nginx -s reload一敲，困扰了一上午的问题竟然好了！\n之前做过区块链项目，有些密码学的基本知识，让我知道，这个大小5kb的文件应该是中间证书。（背景知识：根证书和中间证书的区别）\n用这个中间证书+nginx+https来搜索，让我很快的找到了原因。\n原来，如果在Apache中配置证书时，是有certificate chain这个属性来指定中间证书的。\nNginx没有Certificat Chain这个参数，如果有中间证书，需要把域名证书和中间证书合并，然后指定给ssl_certificate才行。\n重要的事情再说一遍， \u0026gt; 用Nginx配置https证书，如果有中间证书，一定要和域名证书合并, 再指定给ssl_certificate。\n话说，我司的证书是在Go Daddy上买的，下载时没有nginx的选项，所以选择了Apache，中间证书是分开的，就踩了这个坑。如果证书厂商提供了nginx下载选项，那么下载的证书应是合并后的，就应该没有这个问题了.\n总结和反思 虽说，这个问题是有惊无险的解决了，但值得反思和总结的是：\n 公司创立刚满一年，很多机制还是不够健全，证书是到过期了才发现，没有事先的提醒。 在服务器操作配置文件，一定要备份，关键时刻比较文件大小也有奇效！:) 最后，用Nginx配置https证书时，中间证书一定要和域名证书合并！  ","href":"/posts/nginx_https_ssl/","title":"用Nginx配置https证书，你绝对不能忽略这一点！"},{"content":"","href":"/tags/%E7%AC%94%E8%AE%B0/","title":"笔记"},{"content":"","href":"/categories/%E7%AC%94%E8%AE%B0/","title":"笔记"},{"content":"","href":"/tags/sql/","title":"sql"},{"content":"引子 话说，自从前段时间用granafa配好后端微服务prometheus监控的Dashboard后，我就有了一个新习惯，每天上班第一件事就是盯着这个Dashboard瞅一会儿。\n你还别说，很快我就发现了问题，一些名字看似不复杂的查询接口，却慢到要2到3秒，这是很不正常的。\n于是，我就是这样盯上了一个接口。\n排查过程 这是一个查询文章列表的接口，支持分页，最终执行的SQL如下：\nSELECT DISTINCT C.*, B.nickname, D.feed_id, D.home_feed, D.read_scope, D.publish_time FROM XXcloud.mp_pubno_info A, XXcloud.wechat_pubno B, XXcloud.wechat_article C LEFT JOIN XXcloud.mp_feed_info D ON D.element_id = C.article_id AND D.element_type = 3 AND D.valid = 1 AND D.app_id = \u0026#39;pf\u0026#39; WHERE A.app_id = \u0026#39;pf\u0026#39; AND A.pubno = C.pubno AND A.pubno = B.pubno ORDER BY C.create_time DESC LIMIT 0 , 20 咋一看这么多表联查，还有一个左联接，心想能快就奇怪了！\n一开始真不想理这段sql的业务逻辑，就快速用工具分析了一下查询计划，想着如果是没加索引，那偷个懒:）加个索引就好了。\n结果一看，竟然全部都命中索引了… \u0026gt;_\u0026lt;!!!\n心想有点麻烦呀，没办法只能耐着性子一点点看起。\n首先，对于select部分，因为是C表在左的左联，那么distinct关键字是明显不需要的。但是去掉后，也没有快太多。\n接着，因为个人风格偏好，内联查询更喜欢写inner join on，于是，我把sql的from和where整理了一下，虽然看起来规整些，但并无任何提升。\n这时，我把注意力转移到limit部分，心想如果能早点做limit，这样就可以减少表联接笛卡尔积的集合大小。\n突破口就在这里！\n当我把sql调整成，\nSELECT C.*, B.nickname, D.feed_id, D.home_feed, D.read_scope, D.publish_time FROM XXcloud.wechat_article C inner join (select C2.article_id from XXcloud.mp_pubno_info A inner join XXcloud.wechat_article C2 on A.app_id = \u0026#39;sc\u0026#39; and A.pubno = C2.pubno order by C2.create_time desc limit 20) ai on C.article_id = ai.article_id inner join XXcloud.wechat_pubno B on C.pubno = B.pubno left join XXcloud.mp_feed_info D ON D.valid = 1 AND D.app_id = \u0026#39;sc\u0026#39; AND D.element_type = 3 AND D.element_id = C.article_id ORDER BY C.create_time DESC 再分析一下查询计划，\n清爽的看到query cost从1975降到107!\n但还有优化空间，在这里为了能够一句sql实现查询，使用了临时表，实际上是可以在代码中通过两次查询，一次查询出前20的article_id, 第二次查询时，直接把这20个article_id当成in的命中条件即可。\n总结与反思 话说，这次排查慢sql，打破了我原有的一个认知偏误，以为命中了索引查询速度就不会慢；同时也让我加深了对左联加内联查询性能消耗的认识，左联真心是拖油瓶，本质上还是会将一个表的数据全部查出，如果这个表的数据还是逐渐增加的，那么上了生产环境变慢是必然的。\n值得反思的是，目前公司项目的后端是使用的微服务架构，但涉及到数据库查询方面还是比较随便，同库的表连接也许还可以接受，跨库的表连接实在是后患无穷。\n我能想到的未来改进方向是： - 要么是加索引，不断优化查询计划； - 要么就是严格限制单表查询，在代码中完成联接等操作，方便以后分库分表的扩展； - 特别复杂的需要group by的查询考虑场景做离线的ETL，或者用引入ELK。\n最后，各位看官，关于数据库应用查询方面的优化，你们有什么好的实战经验可以分享一下吗？\n","href":"/posts/slow_sql_analysis_1/","title":"为什么所有的查询条件都命中索引还是那么慢？记一次慢查询优化过程"},{"content":"","href":"/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","title":"性能优化"},{"content":"","href":"/series/","title":"Series"},{"content":"","href":"/tags/channel/","title":"channel"},{"content":"","href":"/series/channelx/","title":"channelx"},{"content":"","href":"/tags/golang/","title":"golang"},{"content":"","href":"/categories/toolkit/","title":"toolkit"},{"content":"如果让我和别人说说Golang有什么特点，我首先想到不一定是goroutine，但一定会是channel。\n因为Channel的存在，是让Goroutine威力加成的利器。\n如果用一句话来解释channel的作用，我会说\n Chanel是一个管道，它会让数据流动起来。\n ++那么如何理解这个让数据流程起来呢？++\n假如说你需要对100次请求，做两种比较耗时的操作，然后再统计加权结果，还需要尽可能的并发来提高性能。示例代码如下：\nvar multipleChan = make(chan int, 4) var minusChan = make(chan int, 4) var harvestChan = make(chan int, 4) defer close(multipleChan) defer close(minusChan) defer close(harvestChan) go func() { for i:=1;i\u0026lt;=100;i++{ multipleChan \u0026lt;- i } }() for i:=0; i\u0026lt;4; i++{ go func() { for data := range multipleChan { minusChan \u0026lt;- data * 2 time.Sleep(10* time.Millisecond) } }() go func() { for data := range minusChan { harvestChan \u0026lt;- data - 1 time.Sleep(10* time.Millisecond) } }() } var sum = 0 var index = 0 for data := range harvestChan{ sum += data index++ if index == 100{ break } } fmt.Println(sum) 不要笑这段代码简单，如果考虑到错误处理的情况，那还是有些复杂的。比如，某个环节是遇到错误可以忽略，某个环节是遇到要终止所有操作；再加上，有时只关心第一个满足条件的返回值，还需要超时处理。\n写一遍也许还可以，要是很多地方都要这样写，那真是头大\u0026gt;_\u0026lt;!!!\n重复的代码是万恶之源，Don\u0026rsquo;t repeat yourself是成为优秀工程师的第一步。\n于是，channelx这个库诞生了！\n使用了这个库，实现上述同样的功能，代码是这样子的~~\nvar sum = 0 NewChannelStream(func(seedChan chan\u0026lt;- Result, quitChannel chan struct{}) { for i:=1; i\u0026lt;=100;i++{ seedChan \u0026lt;- Result{Data:i} } close(seedChan) //记得关闭哦~~~ }).Pipe(func(result Result) Result { return Result{Data: result.Data.(int) * 2} }).Pipe(func(result Result) Result { return Result{Data: result.Data.(int) - 1} }).Harvest(func(result Result) { sum += result.Data.(int) }) fmt.Println(sum) 我喜欢链式风格，所以写成这个样子，你也可以拆开来写的。但重点是代码这样写起来是不是很丝滑，有nodejs stream流的快感呢，嘻嘻~~\n除了Pipe-\u0026gt;Harvest的组合，还可以实现Pipe-\u0026gt;Race, Pipe-\u0026gt;Drain, Pipe-\u0026gt;Cancel等操作的组合。\n这些复杂的例子，都可以参照stream_test.go文件中的单元测试来实现，就不一一贴代码出来了哈。\n那么，这个stream又是如何实现的呢？核心就在NewChannelStream和Pipe这个两个函数里。\nfunc NewChannelStream(seedFunc SeedFunc, optionFuncs ...OptionFunc) *ChannelStream { cs := \u0026amp;ChannelStream{ workers: runtime.NumCPU(), optionFuncs: optionFuncs, } for _, of := range optionFuncs { of(cs) } if cs.quitChan == nil { cs.quitChan = make(chan struct{}) } cs.dataChannel = make(chan Item, cs.workers) go func() { inputChan := make(chan Item) go seedFunc(inputChan, cs.quitChan) loop: for { select { case \u0026lt;-cs.quitChan: break loop case res, ok := \u0026lt;-inputChan: if !ok { break loop } select { case \u0026lt;-cs.quitChan: break loop default: } if res.Err != nil { cs.errors = append(cs.errors, res.Err) } if !cs.hasError \u0026amp;\u0026amp; res.Err != nil { cs.hasError = true cs.dataChannel \u0026lt;- res if cs.ape == stop { cs.Cancel() } continue } if cs.hasError \u0026amp;\u0026amp; cs.ape == stop { continue } cs.dataChannel \u0026lt;- res } } safeCloseChannel(cs.dataChannel) }() return cs } func (p *ChannelStream) Pipe(dataPipeFunc PipeFunc, optionFuncs ...OptionFunc) *ChannelStream { seedFunc := func(dataPipeChannel chan\u0026lt;- Item, quitChannel chan struct{}) { wg := \u0026amp;sync.WaitGroup{} wg.Add(p.workers) for i := 0; i \u0026lt; p.workers; i++ { go func() { defer wg.Done() loop: for { select { case \u0026lt;-quitChannel: break loop case data, ok := \u0026lt;-p.dataChannel: if !ok { break loop } select { case \u0026lt;-quitChannel: break loop default: } dataPipeChannel \u0026lt;- dataPipeFunc(data) } } }() } go func() { wg.Wait() safeCloseChannel(dataPipeChannel) }() } mergeOptionFuncs := make([]OptionFunc, len(p.optionFuncs)+len(optionFuncs)+1) copy(mergeOptionFuncs[0:len(p.optionFuncs)], p.optionFuncs) copy(mergeOptionFuncs[len(p.optionFuncs):], optionFuncs) mergeOptionFuncs[len(p.optionFuncs)+len(optionFuncs)] = passByQuitChan(p.quitChan) //这行保证了整个stream中有一个唯一的quitChan  return NewChannelStream(seedFunc, mergeOptionFuncs...) } 代码看着多，刨除初始化的代码、错误处理和退出处理的代码，核心还是通过channel的数据流动。\n首先，NewChannelStream中会新建一个inputChan传入seedFunc，然后数据会通过seedChan(即inputChan)，传到dataChannel。\n然后，当调用Pipe的时候，Pipe函数会自己创建一个seedFunc从上一个channelStream的dataChannel传到dataPipeChannel中。这个Pipe中的seedFunc又会传入NewChannelStream中，产生一个新channelStream对象，这时在新的channelStream中，inputChan即Pipe中的dataPipeChannel，整个数据流就这样串起来了，过程如下：\n inputChan(seedChan)-\u0026gt;dataChannel-\u0026gt;inputChan(dataPipeChannel)-\u0026gt;dataChannel-\u0026gt;\u0026hellip;.\n 分析过源码，再来看使用ChannelStream的例子和直接用Channel的例子，两个dataChannel分别对应的是multipleChan和minusChan，多出的两个inputChan，就是用这个库额外的开销喽。\n原创不易，你的支持就是对我最大的鼓励，欢迎给channelx点个star！:)\n未完待续，channelx中还会陆续增加各种常用场景的channel实现，敬请期待……\n","href":"/posts/channelx_stream/","title":"如何把Golang的channel用的如nodejs的stream一样丝滑"},{"content":"前言 事情的起因是公司之前的CDN服务是通过腾讯云的COSFS来做的，它的好处是可以像使用本地文件系统一样直接操作腾讯云对象存储中的对象，但后来因为性能等因素，我花时间把上传文件到CDN的功能用SDK重写了（*其实可能比搭个COSFS还简单呢*）。\n前端同事恰好也有图床的使用需求，就想让我给他们开个API，这样他们就可以直接通过代码上传文件了，而不用每次都找后端同事帮忙。这件事本身没什么难度，唯一的问题是这个API的安全方面如何保证，至少不能让外人勿用。\n分析 其它业务上的API都是用的用户登录后的token及用户的权限进行验证，眼下这种用于开发需求的API虽然也可以用同样的方式来做，但一方面不够方便（*上传个图还要先登录，想想就麻烦*），另一方面安全性也还是差些（*是不是所有登录的用户都能调用呢？如果要再加权限的限制，也是麻烦*）。\n恰好自己上份工作是做区块链相关的，有一些密码学的基础知识，所以很自然想到用签名验签的方式来做安全验证。\n先简单的解释一下密码学基础知识，常用的加密方式有两大类，一种是对称加密，即加密和解密都是相同的秘钥; 另一种是非对称加密，秘钥有公私钥之分，公钥是用私钥生成的。签名是指要私钥对一段信息的Hash加密，验签是指用私钥对应的公钥来验证一段信息的签名是否和信息匹配。非对称加密原理的保证了签名只能来自于私钥，而只有对应在公钥才能解签。(如果你对这些原理感兴趣，可以自行搜索相关文章哈)\n实现 我们的后端是用的golang，前端是用NodeJS来实现的。非对称加密的实现方式有好几种，考虑到多端调试的成本，同时不想引入过多的第三方包，我这里选择了更加常用的RSA。下面将分为后端和前端两个部分来分别说明。\n后端实现 1 生成密钥。方法有很多，可以ssh的工具来生成，这是是用代码来生成.\nfunc GenerateKey(bits int) (*rsa.PrivateKey, *rsa.PublicKey, error) { private, err := rsa.GenerateKey(rand.Reader, bits) if err != nil { return nil, nil, err } return private, \u0026amp;private.PublicKey, nil } 然后把密钥导出成base64的字符串，方便保存和使用。\nfunc EncodePrivateKey(private *rsa.PrivateKey) []byte { return pem.EncodeToMemory(\u0026amp;pem.Block{ Bytes: x509.MarshalPKCS1PrivateKey(private), Type: \u0026#34;RSA PRIVATE KEY\u0026#34;, }) } func EncodePublicKey(public *rsa.PublicKey) ([]byte, error) { publicBytes, err := x509.MarshalPKIXPublicKey(public) if err != nil { return nil, err } return pem.EncodeToMemory(\u0026amp;pem.Block{ Bytes: publicBytes, Type: \u0026#34;PUBLIC KEY\u0026#34;, }), nil } 代码的话，没什么花头，唯一需要注意的是Type不要乱填，这可是标准哈! pem也是最常用的的密钥的编码方式。\n2 签名解签。\nfunc SignWithSha256Base64(data string, prvKeyBytes []byte) (string, error) { block, _ := pem.Decode(prvKeyBytes) if block == nil { return \u0026#34;\u0026#34;, errors.New(\u0026#34;fail to decode private key\u0026#34;) } privateKey, err := x509.ParsePKCS1PrivateKey(block.Bytes) if err != nil { return \u0026#34;\u0026#34;, err } h := sha256.New() h.Write([]byte([]byte(data))) hash := h.Sum(nil) signature, err := rsa.SignPKCS1v15(rand.Reader, privateKey, crypto.SHA256, hash[:]) if err != nil { return \u0026#34;\u0026#34;, err } out := base64.StdEncoding.EncodeToString(signature) return out, nil } func VerySignWithSha256Base64(originalData, signData string, pubKeyBytes[]byte) (bool, error) { sign, err := base64.StdEncoding.DecodeString(signData) if err != nil { return false ,err } block, _ := pem.Decode(pubKeyBytes) if block == nil { return false, errors.New(\u0026#34;fail to decode public key\u0026#34;) } pub, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil { return false, err } hash := sha256.New() hash.Write([]byte(originalData)) err = rsa.VerifyPKCS1v15(pub.(*rsa.PublicKey), crypto.SHA256, hash.Sum(nil), sign) return err == nil, err } 这里选用的Hash方法是Sha256，在签名和解签时都要用Sha256哦。\n其实，加解密的相关代码在使用起来是比较固定的，但是一定是要记得使用的Hash方式和加解密的方法，要不然\u0026ndash;嘿嘿\u0026ndash;那真是调试到欲哭无泪呀。\n3 经过一层封装，使用起来就很方便啦，下面测试一下。\nfunc TestSignAndVerify(t *testing.T) { sk, pk, _ := GenerateKey(1024) skBytes := EncodePrivateKey(sk) pkBytes, _ := EncodePublicKey(pk) fmt.Println(string(skBytes)) fmt.Println(string(pkBytes)) sig, err := SignWithSha256Base64(\u0026#34;test\u0026#34;, skBytes) if err != nil{ fmt.Printf(\u0026#34;%+v\u0026#34;, err) } fmt.Println(sig) success, err := VerySignWithSha256Base64(\u0026#34;test\u0026#34;, sig, pkBytes) if success { fmt.Println(\u0026#34;pass\u0026#34;) } else { fmt.Printf(\u0026#34;%+v\u0026#34;, err) } } 上述代码可在ksloveyuan/rsautil查看。\n4 接着，我用echo写了一个简单的server端。\npackage main import ( \u0026#34;github.com/ksloveyuan/rsautil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/labstack/echo\u0026#34; ) const PublicKey = `-----BEGIN PUBLIC KEY----- 公钥 -----END PUBLIC KEY-----`` type VerifyArgs struct { Content string `json:\u0026#34;content\u0026#34; description:\u0026#34;\u0026#34; binding:\u0026#34;required\u0026#34; ` Signature string `json:\u0026#34;signature\u0026#34; description:\u0026#34;\u0026#34; binding:\u0026#34;required\u0026#34; ` } func main() { e := echo.New() e.POST(\u0026#34;/verify\u0026#34;, func(c echo.Context) error { args:= VerifyArgs{} if err := c.Bind(\u0026amp;args); err !=nil{ return c.String(http.StatusBadRequest, \u0026#34;参数不正确\u0026#34;) } message := \u0026#34;\u0026#34; if success, _ := rsautil.VerySignWithSha256Base64(args.Content, args.Signature, []byte(PublicKey)); success{ message = \u0026#34;success\u0026#34; } else { message = \u0026#34;fail\u0026#34; } return c.String(http.StatusOK, message) }) e.Logger.Fatal(e.Start(\u0026#34;:1323\u0026#34;)) } 前端实现 前端的主要工作是发起请求，同时附带请求参数的签名。\nlet crypto = require(\u0026#39;crypto\u0026#39;) let request = require(\u0026#39;request\u0026#39;) let sk = `-----BEGIN RSA PRIVATE KEY-----对应的私钥-----END RSA PRIVATE KEY-----` function sendRequest ({ content, signature }) { var bodyData = { content, signature } return new Promise((resolve, reject) =\u0026gt; { request.post({ url: \u0026#39;http://localhost:1323/verify\u0026#39;, body: bodyData, json: true }, function optionalCallback ( err, httpResponse, body ) { if (err) { reject() return console.error(\u0026#39;upload failed:\u0026#39;, err) } console.log(\u0026#39;Upload successful!\u0026#39;, body) resolve() }) }) } async function action() { let signer = crypto.createSign(\u0026#39;RSA-SHA256\u0026#39;) let content = \u0026#39;test_test_test\u0026#39; signer.update(content) let privateKey = {key: sk, format:\u0026#34;pem\u0026#34;, type:\u0026#34;pkcs1\u0026#34;} let signature = signer.sign(privateKey, \u0026#39;base64\u0026#39;) console.log(signature) await sendRequest({ content, signature }) } action()  其中request第三方包，crypto是nodejs自带的库。\n代码中需要注意的地方有两点: 1. 选用的签名方法一定要是RSA-SHA256，否则的话，和后端就对不上了。 2. 使用的私钥的格式参数虽然是默认参数，但最好显示指定哈。\n以上demo的完整代码可在ksloveyuan/ApiSecurityDemo中查看，欢迎star哈。\n写在最后 关于私钥的保存，明文HardCode在代码里自然是一个安全隐患。\n这一点，一方面可以保存在文件里，使用时读取，密钥的安全由保管的人负责（*话说ssh密钥登录就是这样*）;或者是对私钥再做一层AES的加密，每次使用时输入AES加密的Keyword。\n话说回来，安全攻防是没有尽头的，主要还是要看要保证的安全级别而定。\n公司前端的同事，对目前的安全保证已经很满意了。\n","href":"/posts/api_security/","title":"内部API的安全防护怎么搞？密码学中有答案"},{"content":"","href":"/tags/%E5%AE%89%E5%85%A8/","title":"安全"},{"content":"","href":"/tags/ci/","title":"CI"},{"content":"","href":"/categories/step-by-step/","title":"Step by step"},{"content":"前言 公司的代码管理是用的Gitlab, 持续集成(CI)估计是顺手就用了Gitlab的CI（*不要问我为啥不用jenkins*）。\n经过一段时间使用下来，基本功能是够用的，就是差了一个Dashboard来统一查看当前CI的状态，这点还是挺不方便的。\n于是，经过一番搜索，选中了gitlab-monitor，原因吗，一方面比较简洁美观;另一方面，可以docker部署。 搭建步骤  首先拉取镜像  docker pull timoschwarzer/gitlab-monitor  获得gitlab的access token。登录gitlab后，进入用户设置，点击左侧菜单的Access Token，可以看到如下的页面。   然后，输入个名字，设置过期时间，勾选API和Read Repository，就可以创建一个token。 记得一定要复制保存好，回头可是没有地方再看到这个token了！不过也没什么大不了，忘了就再申请一个吗\n 下面，就是启动gitlab-monitor的container了。它支持一些自定义的参数可以在configuration里查询。  我根据自己的偏好，设置如下。\n{ \u0026#34;gitlabApi\u0026#34;: \u0026#34;https://gitlab.******.com/api/v4\u0026#34;, \u0026#34;privateToken\u0026#34;: \u0026#34;*********\u0026#34;, \u0026#34;showStagesNames\u0026#34;: true, \u0026#34;fetchCount\u0026#34;: 40, \u0026#34;pipelinesOnly\u0026#34;: true, \u0026#34;showUsers\u0026#34;: true, \u0026#34;pollingIntervalMultiplier\u0026#34;: 0.2 } 这个参数可以通过环境变量GITLAB_MONITOR_CONFIG传入，于是启动docker的命令如下:\ndocker run -d -p 11080:80 -e GITLAB_MONITOR_CONFIG=\u0026#39;{\u0026#34;gitlabApi\u0026#34;: \u0026#34;https://gitlab.*****.com/api/v4\u0026#34;,\u0026#34;privateToken\u0026#34;: \u0026#34;********\u0026#34;,\u0026#34;showStagesNames\u0026#34;: true,\u0026#34;fetchCount\u0026#34;: 40, \u0026#34;pipelinesOnly\u0026#34;: true, \u0026#34;showUsers\u0026#34;: true,\u0026#34;pollingIntervalMultiplier\u0026#34;: 0.2}\u0026#39; --name=gitlab-monitor timoschwarzer/gitlab-monitor:latest  最后一步，在浏览器里输入localhost:11080就好了。  写在最后 有一个点需要注意一下，我们通过环境变量指定的配置是会保存在浏览器的LocalStorage里的，并且是明文的，理论上这个AccessToken是有泄露的风险的。 但这是gitlab-monitor的实现决定的，除非修改源码。\n","href":"/posts/gitlab_ci_dashboard/","title":"Step by step 搭建Gitlab CI Pipeline的监控Dashboard"},{"content":"","href":"/categories/%E6%8E%92%E9%94%99%E7%AC%94%E8%AE%B0/","title":"排错笔记"},{"content":"前言 事情的起因是某天CTO突然和我说，生产环境的程序CPU有点高，关键是现在也没什么负载，同样的代码在开发环境上CPU就低的多了。\n不用细说，那一定是有什么地方出问题了。\nCTO还说，他pprof过了，占用CPU最高的runtime.futex，还发了一篇相关的文章谁占了该CPU核的30% - 一个较意外的Go性能问题 ，打趣说没准系统负载高了，这个问题就没了。因为原文中写到：\n 必须指出，本问题是因为系统空闲没有goroutine可以调度造成的。显然的，系统繁忙的时候，即CPU资源真正体现价值时，上述30%的%CPU的overhead并不存在，因为大概率下会有goroutine可供调度，无需去做让M去sleep这个很重的操作。\n 然后就把这个锅就“甩”给我了，让我研究一下。毕竟开发环境的负载也没有那么高，但是CPU却蛮正常的。\n分析 一开始我是没什么头绪，顺着CTO提供的线索，搜索了一些runtime.futex的文章，几乎所有文章都会提到以下可能会使CPU占用率高的示例代码：\nvar ticker = time.NewTicker(100 * time.Millisecond) defer ticker.Stop() var counter = 0 for { select { case \u0026lt;-serverDone: return case \u0026lt;-ticker.C: counter += 1 } } 这段代码给我指明了一些方向，我开始全局搜索一些time.NewTicker的代码。\n巧的是，还真让我搜到了一些，其中一个ticker的时间设置的很有问题。\noptions = append(options, metrics.BatchInterval(time.Duration(conf.BatchInterval)))  这里的time.Duration(conf.BatchInterval)没有指定单位，那可就是nano second（纳秒）级别的，这ticker的协程跑起来，没造成死锁，只能说linux服务器的性能好。\n后来，顺藤摸瓜，发现了这个interval其实是promethus的采样interval，promethus只在生产打开了，也可以解释了为什么同样的代码只在生产上出问题。\n解决方法 初步的解决方法很简单，就是给这个interval加上单位，再略微调大一些就好，而且目前我们并没有太重视promethus的性能数据，所以也不是很确定50ms的采样间隔是不是有些过大。\n总结 虽说找到了问题的root cause，但还是有值得改进的地方，比如说，如果一开始就先diff生产和开发的程序的配置有哪些不同，说不定可以更快的解决问题。\n参考文章  分析golang定时器cpu使用率高的现象 ","href":"/posts/golang_high_cpu/","title":"记一次golang程序CPU高的排查过程"},{"content":"","href":"/tags/bft/","title":"BFT"},{"content":"前言 年初找工作时，面过一家自称区块链行业前三的公司（*事实上也差不多*），他们笔试题蛮有意思的，时隔半年，估计他们也更新题库了，就拿出来和大家分享一下。\n题目 )\n翻译如下：\nSandy是一个制作地图的探险家。她从点（0,0）开始探索，每次可以向左、向右、向上或者向下移动一点。例如，如果Sandy站在（x,y）处，她可以移动到(x+1,y),(x-1,y),(x,y+1)或(x,y-1)。她不能跳也不能走对角线方向。\nJohn要阻止Sandy，他会在坐标数字的绝对值之和大于21的地方埋地雷。例如，点（59，-79）有地雷，因为5+7+9+9\u0026gt;21；而点（-113，-104）没有地雷，因为1+1+3+1+0+4\u0026lt;=21。\n如果Sandy踩到地雷，她会死。她不能跳过地雷，必须绕着走。\n请编写一个程序，来计算Sandy从(0,0)开始可以访问的点的数量。\n分析 首先，可以快速判断出这道题考的是图的遍历，遍历的方法无非深度优先，或者广度优先。此题是要计算所有可遍历的点，于是，我选择用广度优先。\n然后，因为Sandy可以向四个方向移动，初步可以判断可以遍历的范围是关于XY轴对称。再则，根据地雷的埋放规则“坐标数字的绝对值之和大于21的地方埋地雷”, 可以进一步推出可以遍历的范围是关于y=x、y=-x、y=0和x=0对称的。举个例子，(56,65),(-56,65),(56,-65),(-56,-65)和(65，56),(-65，56),(65,-56),(-65,-56)都是埋放的地雷的点。\n于是，我们只需要考虑x\u0026gt;=0,y\u0026gt;=0且x\u0026lt;=y的区域，乘以对称的次数，就可以推出所有可以遍历的点。但需要注意的是对于x\u0026gt;0,y\u0026gt;0且x0和y=x且x\u0026gt;0这两条边，只需要乘以4就好，因为它们是被两个区块所共有的，乘以8就算重了；特别需要注意的是(x=0,y=0)这点，是所有可以遍历的区域的中心，乘以1即可。\n编码 按照上述的分析，编码工作就可以依次开始了。\n首先，先定义一个关于的点的结构体，并增加一个计算坐标和的函数。\ntype Point struct { X int Y int } func (p Point) CoordinateSum() int { xNumStrs := strings.Split(strconv.Itoa(p.X), \u0026#34;\u0026#34;) yNumStrs := strings.Split(strconv.Itoa(p.Y), \u0026#34;\u0026#34;) numStrs := append(xNumStrs, yNumStrs...) sum := 0 for _, str := range numStrs { num, _ := strconv.ParseInt(str, 10, 32) sum += int(num) } return sum } CoordinateSum不会改变点的X,Y值，于是，定义和值类型的方法。\n接着，在通用的遍历图算法，需要有个map判断当前点是否遍历过，来剪枝。在本题中，还需要判断当前点是否是地雷，于是，我把这两段逻辑写到了一方法里。\nvar checkedPoints map[Point]bool func CheckPoint(p Point) bool { if _, ok := checkedPoints[p]; ok { return false } if p.Y \u0026gt; p.X || p.X \u0026lt; 0 || p.Y \u0026lt; 0{ return false } return p.CoordinateSum() \u0026lt;= 21 } 全局变量在工程化的代码中是需要尽量避免使用的，这里图方便，权且用一下。\n下面就是广度优先遍历的代码了。\nvar toCheckPoints = list.New() checkedPoints = map[Point]bool{} var point = Point{0, 0} toCheckPoints.PushFront(point) checkedPoints[point] = true for toCheckPoints.Len() \u0026gt; 0 { element := toCheckPoints.Front() point = toCheckPoints.Remove(element).(Point) searchPoint := Point{point.X, point.Y - 1} Search(searchPoint, toCheckPoints) searchPoint = Point{point.X - 1, point.Y} Search(searchPoint, toCheckPoints) searchPoint = Point{point.X + 1, point.Y} Search(searchPoint, toCheckPoints) searchPoint = Point{point.X, point.Y + 1} Search(searchPoint, toCheckPoints) } func Search(searchPoint Point, toCheckPoints *list.List) { if CheckPoint(searchPoint) { checkedPoints[searchPoint] = true toCheckPoints.PushFront(searchPoint) } else { if _, ok := checkedPoints[searchPoint]; !ok { checkedPoints[searchPoint] = false } } } 最后，就是根据遍历的过的点，计算可以遍历点的数量。\npointsOnMap := 0 var minedPoints = list.New() var visiblePoints = list.New() for point, visible := range checkedPoints { if visible { if point.X == 0 \u0026amp;\u0026amp; point.Y == 0 { pointsOnMap += 1 } else if point.Y == 0 || point.X == point.Y { pointsOnMap += 4 } else { pointsOnMap += 8 } visiblePoints.PushFront(point) }else { minedPoints.PushFront(point) } } fmt.Println(\u0026#34;Points on map are\u0026#34;, pointsOnMap) 程序写好，但是不确定对不对怎么办？\n这个吗，就需要把可以遍历的点和地雷分别画出来，就可以知道。\n这里，我选择了用Echarts的散点图的在线示例来画。地址是https://echarts.baidu.com/examples/editor.html?c=scatter-simple\n使用的配置是：\noption = { dataZoom: [ { type: \u0026#39;slider\u0026#39;, show: true, xAxisIndex: [0], start: 0, end: 500, }, { type: \u0026#39;slider\u0026#39;, show: true, yAxisIndex: [0], start: 0, end: 250 } ], xAxis: {}, yAxis: {}, series: [{ symbolSize: 1, data: [ [10.0, 8.04], ], type: \u0026#39;scatter\u0026#39; }] }; 用算出来的点，替换data部分就可以画出来了。\n可以遍历的点的图是： 地雷的点的图是： 完整代码 package main import ( \u0026#34;container/list\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; ) type Point struct { X int Y int } func (p Point) CoordinateSum() int { xNumStrs := strings.Split(strconv.Itoa(p.X), \u0026#34;\u0026#34;) yNumStrs := strings.Split(strconv.Itoa(p.Y), \u0026#34;\u0026#34;) numStrs := append(xNumStrs, yNumStrs...) sum := 0 for _, str := range numStrs { num, _ := strconv.ParseInt(str, 10, 32) sum += int(num) } return sum } var checkedPoints map[Point]bool func main() { var toCheckPoints = list.New() checkedPoints = map[Point]bool{} var point = Point{0, 0} toCheckPoints.PushFront(point) checkedPoints[point] = true for toCheckPoints.Len() \u0026gt; 0 { element := toCheckPoints.Front() point = toCheckPoints.Remove(element).(Point) searchPoint := Point{point.X, point.Y - 1} Search(searchPoint, toCheckPoints) searchPoint = Point{point.X - 1, point.Y} Search(searchPoint, toCheckPoints) searchPoint = Point{point.X + 1, point.Y} Search(searchPoint, toCheckPoints) searchPoint = Point{point.X, point.Y + 1} Search(searchPoint, toCheckPoints) } //fmt.Println(len(checkedPoints)) \t//fmt.Println(checkedPoints)  pointsOnMap := 0 var minedPoints = list.New() var visiblePoints = list.New() for point, visible := range checkedPoints { if visible { if point.X == 0 \u0026amp;\u0026amp; point.Y == 0 { pointsOnMap += 1 } else if point.Y == 0 || point.X == point.Y { pointsOnMap += 4 } else { pointsOnMap += 8 } visiblePoints.PushFront(point) }else { minedPoints.PushFront(point) } } fmt.Println(\u0026#34;Points on map are\u0026#34;, pointsOnMap) //for e := minedPoints.Front(); e != nil; e = e.Next() { \t//\tp := e.Value.(Point) \t//\tfmt.Println(\u0026#34;[\u0026#34;, p.X, \u0026#34;,\u0026#34;, p.Y,\u0026#34;],\u0026#34;) \t//}  } func Search(searchPoint Point, toCheckPoints *list.List) { if CheckPoint(searchPoint) { checkedPoints[searchPoint] = true toCheckPoints.PushFront(searchPoint) } else { if _, ok := checkedPoints[searchPoint]; !ok { checkedPoints[searchPoint] = false } } } func CheckPoint(p Point) bool { if _, ok := checkedPoints[p]; ok { return false } if p.Y \u0026gt; p.X || p.X \u0026lt; 0 || p.Y \u0026lt; 0{ return false } return p.CoordinateSum() \u0026lt;= 21 } 答案：287881\n后记 笔试我是答对了，但是也没能得到面试机会……\nHR反馈说，面试官觉得我的年龄和实力不符合团队结构的期望 ˚‧º·(˚ ˃̣̣̥⌓˂̣̣̥ )‧º·˚\n那次面试，也最终断了我继续在区块链行业奋斗的希望。没办法，我可是要工作养家的男人哈。\n","href":"/posts/interview_bft_1/","title":"解析一道区块链行业前三公司的笔试题"},{"content":"","href":"/tags/%E9%9D%A2%E8%AF%95/","title":"面试"},{"content":"","href":"/categories/%E9%9D%A2%E8%AF%95/","title":"面试"},{"content":"在上一篇文章，我分享了自己在新增和更新的场景下，自己使用gorm的一些心得和扩展。本文，我将分享一些在查询的方面的心得。\n首先，我把查询按照涉及到的表的数量分为： - 单表查询 - 多表查询\n按照查询范围又可以分为： - 查询一个 - 范围查询 - 查询一组 - 有序查询 - 查询前几个 - 分页查询\n在日常使用中，单表查询占据了多半的场景，把这部分的代码按照查询范围做一些封装，可以大大减少冗余的代码。\n单表查询 于是，我仿照gorm API的风格，做了如下的封装：\nps：以下例子均以假定已定义user对象\n查询一个 func (dw *DBExtension) GetOne(result interface{}, query interface{}, args ...interface{}) (found bool, err error) { var ( tableNameAble TableNameAble ok bool ) if tableNameAble, ok = query.(TableNameAble); !ok { if tableNameAble, ok = result.(TableNameAble); !ok { return false, errors.New(\u0026#34;neither the query nor result implement TableNameAble\u0026#34;) } } err = dw.Table(tableNameAble.TableName()).Where(query, args...).First(result).Error if err == gorm.ErrRecordNotFound { dw.logger.LogInfoc(\u0026#34;mysql\u0026#34;, fmt.Sprintf(\u0026#34;record not found for query %s, the query is %+v, args are %+v\u0026#34;, tableNameAble.TableName(), query, args)) return false, nil } if err != nil { dw.logger.LogErrorc(\u0026#34;mysql\u0026#34;, err, fmt.Sprintf(\u0026#34;failed to query %s, the query is %+v, args are %+v\u0026#34;, tableNameAble.TableName(), query, args)) return false, err } return true, nil } 这段值得说明的就是对查询不到数据时的处理，gorm是报了gorm.ErrRecordNotFound的error, 我是对这个错误做了特殊处理，用found这个boolean值表述这个特殊状态。\n调用代码如下：\ncondition := User{Id:1} result := User{} if found, err := dw.GetOne(\u0026amp;result, condition); !found { //not found  if err != nil { // has error  return err } } 也可以这样写，更加灵活的指定的查询条件：\nresult := User{} if found, err := dw.GetOne(\u0026amp;result, \u0026#34;id = ？\u0026#34;， 1); !found { //not found  if err != nil { // has error  return err } } 两种写法执行的语句都是：\nselect * from test.user where id = 1 范围查询 针对四种范国查询，我做了如下封装：\nfunc (dw *DBExtension) GetList(result interface{}, query interface{}, args ...interface{}) error { return dw.getListCore(result, \u0026#34;\u0026#34;, 0, 0, query, args) } func (dw *DBExtension) GetOrderedList(result interface{}, order string, query interface{}, args ...interface{}) error { return dw.getListCore(result, order, 0, 0, query, args) } func (dw *DBExtension) GetFirstNRecords(result interface{}, order string, limit int, query interface{}, args ...interface{}) error { return dw.getListCore(result, order, limit, 0, query, args) } func (dw *DBExtension) GetPageRangeList(result interface{}, order string, limit, offset int, query interface{}, args ...interface{}) error { return dw.getListCore(result, order, limit, offset, query, args) } func (dw *DBExtension) getListCore(result interface{}, order string, limit, offset int, query interface{}, args []interface{}) error { var ( tableNameAble TableNameAble ok bool ) if tableNameAble, ok = query.(TableNameAble); !ok { // type Result []*Item{} \t// result := \u0026amp;Result{} \tresultType := reflect.TypeOf(result) if resultType.Kind() != reflect.Ptr { return errors.New(\u0026#34;result is not a pointer\u0026#34;) } sliceType := resultType.Elem() if sliceType.Kind() != reflect.Slice { return errors.New(\u0026#34;result doesn\u0026#39;t point to a slice\u0026#34;) } // *Item \titemPtrType := sliceType.Elem() // Item \titemType := itemPtrType.Elem() elemValue := reflect.New(itemType) elemValueType := reflect.TypeOf(elemValue) tableNameAbleType := reflect.TypeOf((*TableNameAble)(nil)).Elem() if elemValueType.Implements(tableNameAbleType) { return errors.New(\u0026#34;neither the query nor result implement TableNameAble\u0026#34;) } tableNameAble = elemValue.Interface().(TableNameAble) } db := dw.Table(tableNameAble.TableName()).Where(query, args...) if len(order) != 0 { db = db.Order(order) } if offset \u0026gt; 0 { db = db.Offset(offset) } if limit \u0026gt; 0 { db = db.Limit(limit) } if err := db.Find(result).Error; err != nil { dw.logger.LogErrorc(\u0026#34;mysql\u0026#34;, err, fmt.Sprintf(\u0026#34;failed to query %s, query is %+v, args are %+v, order is %s, limit is %d\u0026#34;, tableNameAble.TableName(), query, args, order, limit)) return err } return nil } 为了减少冗余的代码，通用的逻辑写在getListCore函数里，里面用到了一些golang反射的知识。\n但只要记得golang的反射和其它语言的反射最大的不同，是golang的反射是基本值而不是类型的，一切就好理解了。\n其中的一个小技巧是如何判断一个类型是否实现了某个接口，用到了指向nil的指针。\nelemValue := reflect.New(itemType) elemValueType := reflect.TypeOf(elemValue) tableNameAbleType := reflect.TypeOf((*TableNameAble)(nil)).Elem() if elemValueType.Implements(tableNameAbleType) { return errors.New(\u0026#34;neither the query nor result implement TableNameAble\u0026#34;) } 关于具体的使用，就不再一一举例子了，熟悉gorm api的同学可以一眼看出。\n多表查询 关于多表查询，因为不同场景很难抽取出不同，也就没有再做封装，但是我的经验是优先多使用gorm的方法，而不是自己拼sql。你想要做的gorm都可以实现。\n这里，我偷个懒，贴出自己在项目中写的最复杂的一段代码，供各位看官娱乐。\n一个复杂的例子 这段代码是从埋点数据的中间表，为了用通用的代码实现不同展示场景下的查询，代码设计的比较灵活，其中涉及了关联多表的查询，按查询条件动态过滤和聚合，还有分页查询的逻辑。\nfunc buildCommonStatisticQuery(tableName, startDate, endDate string) *gorm.DB { query := models.DB().Table(tableName) if startDate == endDate || endDate == \u0026#34;\u0026#34; { query = query.Where(\u0026#34;date = ?\u0026#34;, startDate) } else { query = query.Where(\u0026#34;date \u0026gt;= ? and date \u0026lt;= ?\u0026#34;, startDate, endDate) } return query } func buildElementsStatisticQuery(startDate, endDate, elemId string, elemType int32) *gorm.DB { query := buildCommonStatisticQuery(\u0026#34;spotanalysis.element_statistics\u0026#34;, startDate, endDate) if elemId != \u0026#34;\u0026#34; \u0026amp;\u0026amp; elemType != 0 { query = query.Where(\u0026#34;element_id = ? and element_type = ?\u0026#34;, elemId, elemType) } return query } func CountElementsStatistics(count *int32, startDate, endDate, instId, appId, elemId string, elemType int32, groupFields []string ) error { query := buildElementsStatisticQuery(startDate, endDate, elemId, elemType) query = whereInstAndApp(query, instId, appId) if len(groupFields) != 0 { query = query.Select(fmt.Sprintf(\u0026#34;count(distinct(concat(%s)))\u0026#34;, strings.Join(groupFields, \u0026#34;,\u0026#34;))) } else { query = query.Select(\u0026#34;count(id)\u0026#34;) } query = query.Count(count) return query.Error } func GetElementsStatistics(result interface{}, startDate, endDate, instId, appId, elemId string, elemType int32, groupFields []string, orderBy string, ascOrder bool, limit, offset int32) error { query := buildElementsStatisticQuery(startDate, endDate, elemId, elemType) if len(groupFields) != 0 { groupBy := strings.Join(groupFields, \u0026#34;`,`\u0026#34;) groupBy = \u0026#34;`\u0026#34; + groupBy + \u0026#34;`\u0026#34; query = query.Group(groupBy) query = havingInstAndApp(query, instId, appId) sumFields := strings.Join([]string{ \u0026#34;SUM(`element_statistics`.`mp_count`) AS `mp_count`\u0026#34;, \u0026#34;SUM(`element_statistics`.`h5_count`) AS `h5_count`\u0026#34;, \u0026#34;SUM(`element_statistics`.`total_count`) AS `total_count`\u0026#34;, \u0026#34;SUM(`element_statistics`.`collection_count`) AS `collection_count`\u0026#34;, \u0026#34;SUM(`element_statistics`.`mp_share_count`) AS `mp_share_count`\u0026#34;, \u0026#34;SUM(`element_statistics`.`h5_share_count`) AS `h5_share_count`\u0026#34;, \u0026#34;SUM(`element_statistics`.`poster_share_count`) AS `poster_share_count`\u0026#34;, \u0026#34;SUM(`element_statistics`.`total_share_count`) AS `total_share_count`\u0026#34;, }, \u0026#34;,\u0026#34;) query = query.Select(groupBy + \u0026#34;,\u0026#34; + sumFields) } else { query = whereInstAndApp(query, instId, appId) } query = getPagedList(query, orderBy, ascOrder, limit, offset) return query.Find(result).Error } func getPagedList(query *gorm.DB, orderBy string, ascOrder bool, limit , offset int32) *gorm.DB { if orderBy != \u0026#34;\u0026#34; { if ascOrder { orderBy += \u0026#34; asc\u0026#34; } else { orderBy += \u0026#34; desc\u0026#34; } query = query.Order(orderBy) } if offset != 0 { query = query.Offset(offset) } if limit != 0 { query = query.Limit(limit) } return query } func whereInstAndApp(query *gorm.DB, instId string, appId string) *gorm.DB { query = query.Where(\u0026#34;inst_id = ?\u0026#34;, instId) if appId != \u0026#34;\u0026#34; { query = query.Where(\u0026#34;app_id = ?\u0026#34;, appId) } return query } func havingInstAndApp(query *gorm.DB, instId string, appId string) *gorm.DB { query = query.Having(\u0026#34;inst_id = ?\u0026#34;, instId) if appId != \u0026#34;\u0026#34; { query = query.Having(\u0026#34;app_id = ?\u0026#34;, appId) } return query } 感谢各位看官耐心看完，如果本文对你有用，请点个赞~~~\n如果能到代码仓库：Github:Ksloveyuan/gorm-ex 给个✩star✩, 楼主就更加感谢了！\n","href":"/posts/gorm_extension_2/","title":"Gorm的使用心得和一些常用扩展(二)"},{"content":"","href":"/tags/gorm/","title":"gorm"},{"content":"","href":"/series/gorm/","title":"gorm"},{"content":"","href":"/categories/%E5%BF%83%E5%BE%97/","title":"心得"},{"content":"Gorm是golang的一个orm框架，它提供了对数据库操作的封装，使用起来相当便利。\n但在项目开发中，代码写的多了，还是发现在它之上还是有再次封装的空间，比如说添加错误日志、或者是一些使用频率非常高的对单个表的条件查询、分页查询、数据更新等。再则是，关于相同的功能操作，gorm也提供多种实现方式，对新学多少有些困惑，不知道该用哪个好。\n于是，我基于自己在项目中的使用经验和编码习惯，做了如下一些扩展，供大家参考。\n准备 为了兼容gorm的使用方法，我使用了内嵌类型来扩展。 定义如下：\ntype DBExtension struct { *gorm.DB logger DBLogger } 这样子定义的wrapper对象是最小侵入式的扩展，不仅可以直接点出gorm的原有方法，也可以点出扩展的方法。\n新增 关于新建数据，我建议使用Save方法，当匹配主键的数据不存在时，它的效果是插入一条新数据，而当匹配主键的数据存在时，则更新全部字段，再说一遍，它会更新全部字段！\n无论字段是否做了修改或者是否是定义类型的默认值。\n请再次注意：默认值是否生效在gorm的不同方法中处理的方式是不一样的，需要非常小心才行。\n举个例子，如果你定义了一个User的结构体，里面有个Age的字段类型是int。（*注：以后的例子，都默认已定义这个结构体*）\ntype User struct { Id int `gorm:\u0026#34;column:id; type:int(11);primary_key\u0026#34;` Name string `gorm:\u0026#34;column:name; type:varchar(32);\u0026#34;` Age int `gorm:\u0026#34;column:age; type:int(11);\u0026#34;` Description string `gorm:\u0026#34;column:description; type:varchar(512);\u0026#34;` } func (User) TableName() string { return \u0026#34;test.user\u0026#34; } ++请特别注意Id的定义中的primary_key, 如果没有加个这个Save方法是无法正常工作的。++\n如果在定义时，没有给Age赋值，那么这条数据的Age将被置为0。\n对于新增数据，可能问题不大，但是对于数据更新，那这就可就是一个隐晦的bug了！\n那既然Save方法有这样一个坑，为什么还要用它呢？\n简单来说，不用显示的判断是新增数据和更新数据，可以让代码更加简洁，利大于弊，不是吗？\n扩展代码如下,增加了一些错误判断和日志：\ntype TableNameAble interface { TableName() string } // Update All Fields func (dw *DBExtension) SaveOne(value TableNameAble) error { tableNameAble, ok := value.(TableNameAble) if !ok { return errors.New(\u0026#34;value doesn\u0026#39;t implement TableNameAble\u0026#34;) } var err error if err = dw.Save(value).Error; err != nil { dw.logger.LogErrorc(\u0026#34;mysql\u0026#34;, err, fmt.Sprintf(\u0026#34;Failed to save %s, the value is %+v\u0026#34;, tableNameAble.TableName(), value)) } return err } 使用代码如下：\nuser1 := User{Id:1, Name:\u0026#34;Jeremy\u0026#34;, Age: 30, Description: \u0026#34;A gopher\u0026#34;} if err := dw.SaveOne(\u0026amp;instInfo); err != nil{ // error handling  return err } 当记录不存在时，执行的Sql语句是：\ninsert into test.user(id ,name, age, description) values(1, \u0026#34;Jeremy\u0026#34;, 30, \u0026#34;A gopher\u0026#34;) 当记录存在时，执行的语句就是：\nupdate test.user set name = \u0026#34;Jeremy\u0026#34;, age = 30, description = \u0026#34;A gohper\u0026#34; where id = 1 这样写新建，还兼顾了全字段更新的情况，是不是一举两得呢？\nPS: 如果主键Id是一个自增列，在新建时，可以不用给Id赋值。当数据成功插入后，这条数据的Id还会自动更新到Id字段，这个特性在一些场景下特别有用。\n更新 首先，按照更新的字段的范围可以分为： - 全量更新 - 条件更新\n下面将分这两种情况分别说明：\n全量更新 SaveOne方法是全量更新，但大部分情况是，可能只是更新某条数据的部分字段，又或者是只想更新改过的字段。关于这部分操作，gorm虽然提供了很多操作方法，但也是最让人困惑的。\n在这种场景我常用的处理方式有两种，一是定义一个专门的结构体，如：\ntype UserDesc struct { Id int `gorm:\u0026#34;column:id; type:int(11);primary_key\u0026#34;` Description string `gorm:\u0026#34;column:description; type:varchar(512);\u0026#34;` } func (UserDesc) TableName() string { return \u0026#34;test.user\u0026#34; } 这时就可以使用SaveOne方法，用如下方式更新：\nuserDesc := UserDesc{Id:1, Description: \u0026#34;A programmer\u0026#34;} if err := dw.SaveOne(\u0026amp;userDesc); err != nil{ // error handling  return err } 执行的sql语句是：\nupdate test.user set description = \u0026#34;A programmer\u0026#34; where id = 1 条件更新 但是更多的时候，是想按匹配条件更新的匹配的数据，这时SaveOne就无法满足了。于是，我做了如下扩展：\nconst table_name = \u0026#34;$Table_Name$\u0026#34; type UpdateAttrs map[string]interface{} func NewUpdateAttrs(tableName string) UpdateAttrs { attrMap := make(map[string]interface{}) attrMap[table_name] = tableName return attrMap } // Update selected Fields, if attrs is an object, it will ignore default value field; if attrs is map, it will ignore unchanged field. func (dw *DBExtension) Update(attrs interface{}, query interface{}, args ...interface{}) error { var ( tableNameAble TableNameAble ok bool tableName string ) if tableNameAble, ok = query.(TableNameAble); ok { tableName = tableNameAble.TableName() }else if tableNameAble, ok = attrs.(TableNameAble); ok { tableName = tableNameAble.TableName() } else if attrMap, isUpdateAttrs := attrs.(UpdateAttrs); isUpdateAttrs { tableName = attrMap[table_name].(string) delete(attrMap, table_name) } if tableName == \u0026#34;\u0026#34; { return errors.New(\u0026#34;can\u0026#39;t get table name from both attrs and query\u0026#34;) } var err error db := dw.Table(tableName).Where(query, args...).Update(attrs) if err = db.Error; err != nil { dw.logger.LogErrorc(\u0026#34;mysql\u0026#34;, err, fmt.Sprintf(\u0026#34;failed to update %s, query is %+v, args are %+v, attrs is %+v\u0026#34;, tableName, query, args, attrs)) } if db.RowsAffected == 0 { dw.logger.LogWarnc(\u0026#34;mysql\u0026#34;,nil, fmt.Sprintf(\u0026#34;No rows is updated.For %s, query is %+v, args are %+v, attrs is %+v\u0026#34;, tableName, query, args, attrs)) } return err } 下面，我将结合Sql语句，逐一解释如何使用。\n还是先以要执行下面这条语句为例：\nupdate test.user set description = \u0026#34;A programmer\u0026#34; where id = 1 现在，可以有如下几种实现方式\n 写法一  udateAttrs := User{Description: \u0026#34;A programmer\u0026#34;} condition := User{Id: 1} if err := dw.Update(\u0026amp;udateAttrs, condition); err != nil{ // error handling  return err }  写法二\nudateAttrs := User{Description: \u0026#34;A programmer\u0026#34;} if err := dw.Update(\u0026amp;udateAttrs, \u0026#34;id = ?\u0026#34;, 1); err != nil{ // error handling return err }  写法三 ```go udateAttrs := NewUpdateAttrs(\u0026ldquo;test.user\u0026rdquo;) udateAttrs[\u0026ldquo;description\u0026rdquo;] = \u0026ldquo;A programmer\u0026rdquo;  if err := dw.Update(\u0026amp;udateAttrs, \u0026ldquo;id = ?\u0026rdquo;, 1); err != nil{ // error handling return err } ```\n 写法四 ```go udateAttrs := NewUpdateAttrs(\u0026ldquo;test.user\u0026rdquo;) udateAttrs[\u0026ldquo;description\u0026rdquo;] = \u0026ldquo;A programmer\u0026rdquo; condition := User{Id: 1}\n  if err := dw.Update(\u0026amp;udateAttrs, condition); err != nil{ // error handling return err }\n 咋一看，四种写法很相似。那么，为什么要搞这么多种写法呢？ 这可是不是为了炫耀回字的几种写法, 而是因为gorm原生的Update方法对于struct的参数是会忽略默认值的。 比如说，如果你想把descritpion清空，如果像下面这样写： ```go udateAttrs := User{Description: \u0026quot;\u0026quot;} condition := User{Id: 1} if err := dw.Update(\u0026amp;udateAttrs, condition); err != nil{ // error handling return err }  descritpion是不会被更新的，这是就需要写法三或者写法四了，以写法四为例\nudateAttrs := NewUpdateAttrs(\u0026#34;test.user\u0026#34;) udateAttrs[\u0026#34;description\u0026#34;] = \u0026#34;\u0026#34; condition := User{Id: 1} if err := dw.Update(\u0026amp;udateAttrs, condition); err != nil{ // error handling  return err } 才会如愿执行：\nupdate test.user set description = \u0026#34;\u0026#34; where id = 1 而写法二（三）的强大之处在于可以更自由的指定匹配条件，比如：\nudateAttrs := User{Description: \u0026#34;A programmer\u0026#34;} if err := dw.Update(\u0026amp;udateAttrs, \u0026#34;id in (?) and age \u0026gt; ? and description != ?\u0026#34;, []int{1,2}, 30, \u0026#34;\u0026#34;); err != nil{ // error handling  return err } 执行的sql是：\nupdate test.user set description = \u0026#34;A programmer\u0026#34; where id in (1,2) and age \u0026gt; 30 and description != \u0026#39;\u0026#39; 未完待续……\n代码地址：Github:Ksloveyuan/gorm-ex\n","href":"/posts/gorm_extension_1/","title":"Gorm的使用心得和一些常用扩展(一)"},{"content":"","href":"/tags/elk/","title":"ELK"},{"content":"这周要开始做埋点日记的分析，初步调研后，准备用filebeat+logstash+mongodb来做。\n基于golang写的filebeat比较轻量，解压后就可以直接用了，而logstash还有好多依赖要装，所以毫不犹豫就选择用docker来部署。\n因为是现学现用，时间也有些紧，再加上完全是新手入门，看到文档Configuaring Logstash for Docker中Bind-mounted settings files这段后，\n就自己定义了一个logstash.yml\ninput{ beats { port =\u0026gt; 5044 } } output{ mongodb { uri =\u0026gt; \u0026#34;mongodb://localhost:27017\u0026#34; database =\u0026gt; \u0026#34;spot_logs\u0026#34; collection =\u0026gt; \u0026#34;raw_data\u0026#34; } } 心想着这样通过volume挂进去就可以用了。\ndocker run --rm -it -v ./logstash.yml:/usr/share/logstash/config/logstash.yml docker.elastic.co/logstash/logstash:7.2.0 然后，悲剧开始了~~~\n首先，我定义的其实是一个.conf文件，而不是logstash.yml。\n于是，刚一启动就报错了。\n当我经过一番搜索，知道这其实是一个conf文件后,就直接改把它的后缀名改成了.conf,然后执行了\ndocker run --rm --network host -it -v ./logstash.conf:/usr/share/logstash/config/logstash.conf docker.elastic.co/logstash/logstash:7.2.0 然后，“奇迹发生”了~~filebeat发过来日志，logstash都能收到，而且还打印了出来（*好神奇，那可是我第一次跑通filebeat+logstash*），但是还没开心1分钟，就发现mongodb里根本没数据。\n然后，没有方向的我，开始了一通乱试（*略去不表，其实都是泪*），白白耗费了一个下午加晚上也没找到原因（*那时真是心情沉重，想着这个sprint估计有点难交差了！*）。\n回到家后，洗了澡，重新开始思考这个问题的时候，我突然意识到，可能我设置的配置根本就不起作用，现在的行为没准是logstash镜像的默认行为。（*在时间压力下，现学现用，很容易钻牛角尖，这时暂停下来，平静心情，换个思路很重要！*）\n查了一下logstash官方的dockerfile也没发现什么，到是在一篇搜索到文章中，发现可能是e受容器里的pipelines.yml的影响。\n当我打开容器里的/usr/share/logstash/config/pipelines.yml的时候，看见：\n- pipeline.id: main path.config: \u0026#34;/usr/share/logstash/pipeline\u0026#34; 再打开 /usr/share/logstash/pipeline，看到：\ninput { beats { port =\u0026gt; 5044 } } output { stdout { codec =\u0026gt; rubydebug } }  真是一口老血喷出来~心想好坑呀，隐藏的这么深！\n于是，仿造这个pipelines.yml，也写了个pipelines.yml，把config指向自己的配置。\n- pipeline.id: main path.config: \u0026#34;/usr/share/logstash/config/logstash.conf\u0026#34; pipeline.workers: 3 再挂载进docker启动后，看到mongodb的报错信息后，就知道自己的设置终于生效了。\n报错的原因，是因为logstash-output-mongodb这个output默认是没有的，需要自己装好，解决方法也很简单，自定义一个dockerfile，做一个安装好logstash-output-mongodb的镜像就好。\n同时，在这里我也把自己写的放在config文件里的pipelines.yml和logstash.conf拷了进去，具体内容如下；\nFROM docker.elastic.co/logstash/logstash:7.2.0 RUN rm -f /usr/share/logstash/pipeline/logstash.conf COPY ./config/ /usr/share/logstash/config/ RUN logstash-plugin install logstash-output-mongodb  然后运行：\ndocker build -f logstash.dockerfile -t mine/logstash:1.0 最后定义了一个docker-compose.logstash.yml文件：\nversion: \u0026#39;3\u0026#39; services: logstash: image: mine/logstash:1.0 restart: always container_name: finxos_logstash network_mode: \u0026#39;host\u0026#39; volumes: - \u0026#34;$PWD/config/logstash.conf:/usr/share/logstash/config/logstash.conf\u0026#34; depends_on: - mongodb mongodb: image: mongo:4.0 restart: always container_name: finxos_mongodb volumes: - \u0026#34;$PWD/mongodb_data:/data/db\u0026#34; network_mode: \u0026#39;host\u0026#39; 这样就可以通过下面的命令一键启动了。\ndocker-compose -f docker-compose.logstash.yml up 写在最后 在下笔前，我是心想着写下自己的踩坑经验，估计会对他人有用。\n但是写着的时候，才发现我觉得很坑的默认行为，其实在Configuaring Logstash for Docker的Pipeline Configuration章节里有提到。\n而当时的我急着赶紧用起来，看到Pipeline也不知道是干什么的（*其实现在也不是很清楚*），就直接跳到Settings章节了。\n真的是要好好看文档！抓住重要信息呀！\n但是再一想，即再来一次，以当时的我刚刚接触filebeat+logstash, docker也好久不用了的状态，还面临着完成业务需求的紧迫感，大概率还是会略过这段。\n现学现用，真的很痛苦！\n这期间，关键是要准确的定位问题，然后逢山开路，遇水搭桥，其实也不失为一次蜕变的体验！\n而关键的关键在于，要相信自己最终还是会搞定的。\n","href":"/posts/logstash_docker_note/","title":"Logstash Docker部署的踩坑笔记"},{"content":"","href":"/categories/%E8%B8%A9%E5%9D%91%E7%AC%94%E8%AE%B0/","title":"踩坑笔记"},{"content":"","href":"/authors/","title":"Authors"},{"content":"","href":"/page/","title":"Pages"},{"content":"","href":"/search/","title":"Search"},{"content":"","href":"/%E6%B5%B7%E4%B9%8B%E6%96%B9/","title":"海之方"}]
